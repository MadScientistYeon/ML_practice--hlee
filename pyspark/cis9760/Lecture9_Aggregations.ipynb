{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "specified-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "#findspark.find()\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ad7dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c301f6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(approx_count_distinct(salary)=6)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approx_count_distinct() function returns the count of distinct items in a group.\n",
    "# much faster at approximately counting the distinct records rather than doing an exact count\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "df.select(approx_count_distinct(\"salary\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804767a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(salary)=3400.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df.select(avg(\"salary\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031b0284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to grab the value, 3400, ....\n",
    "df.select(avg(\"salary\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc11d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(collect_set(salary)=[4600, 3000, 3900, 4100, 3300, 2000])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values in col\n",
    "from pyspark.sql.functions import collect_set\n",
    "df.select(collect_set(\"salary\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44442f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|8                                 |\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count distinct \n",
    "from pyspark.sql.functions import countDistinct\n",
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe2e032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT department, salary)=8)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also collect to grab `8` -- question: how?\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71da0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(countDistinct(\"department\", \"salary\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93bf8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(salary)=10)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count can be SLOW for big datasets\n",
    "from pyspark.sql.functions import count\n",
    "df.select(count(\"salary\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c585ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|3000         |\n",
      "+-------------+\n",
      "\n",
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|4100        |\n",
      "+------------+\n",
      "\n",
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|4600       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|2000       |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stats\n",
    "from pyspark.sql.functions import first, last, max, min\n",
    "df.select(first(\"salary\")).show(truncate=False)\n",
    "df.select(last(\"salary\")).show(truncate=False)\n",
    "df.select(max(\"salary\")).show(truncate=False)\n",
    "df.select(min(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea8e4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-------+\n",
      "|first_sal|last_sal|max_sal|min_sal|\n",
      "+---------+--------+-------+-------+\n",
      "|3000     |4100    |4600   |2000   |\n",
      "+---------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All at once\n",
    "df.select(\n",
    "    first(\"salary\").alias(\"first_sal\"), \n",
    "    last(\"salary\").alias(\"last_sal\"),\n",
    "    max(\"salary\").alias(\"max_sal\"),\n",
    "    min(\"salary\").alias(\"min_sal\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22a65ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------------+\n",
      "|employee_name|department|compensation|\n",
      "+-------------+----------+------------+\n",
      "|        James|     Sales|        3000|\n",
      "|      Michael|     Sales|        4600|\n",
      "|       Robert|     Sales|        4100|\n",
      "|        Maria|   Finance|        3000|\n",
      "|        James|     Sales|        3000|\n",
      "|        Scott|   Finance|        3300|\n",
      "|          Jen|   Finance|        3900|\n",
      "|         Jeff| Marketing|        3000|\n",
      "|        Kumar| Marketing|        2000|\n",
      "|         Saif|     Sales|        4100|\n",
      "+-------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can rename the columns\n",
    "df.withColumnRenamed('salary', 'compensation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f065cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ^^^ question: does this change original df?\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09f4f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------------+\n",
      "|employee_name|department|compensation|\n",
      "+-------------+----------+------------+\n",
      "|        James|     Sales|        3000|\n",
      "|      Michael|     Sales|        4600|\n",
      "|       Robert|     Sales|        4100|\n",
      "|        Maria|   Finance|        3000|\n",
      "|        James|     Sales|        3000|\n",
      "|        Scott|   Finance|        3300|\n",
      "|          Jen|   Finance|        3900|\n",
      "|         Jeff| Marketing|        3000|\n",
      "|        Kumar| Marketing|        2000|\n",
      "|         Saif|     Sales|        4100|\n",
      "+-------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.withColumnRenamed('salary', 'compensation')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-charity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
